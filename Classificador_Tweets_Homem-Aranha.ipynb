{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Arthur Pansini\n",
    "\n",
    "Nome: Caio Ribeiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualiza√ß√£o\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tema escolhido para a realiza√ß√£o desse projeto foi o super her√≥i Homem Aranha, personagem que possui uma franquia de jogos vinculados a empresa Sony, al√©m de uma s√©rie de obras cinematogr√°ficas produzidas pela Marvel Studios.\n",
    "\n",
    "O objetivo que almejamos com o projeto √© de analisar o que os consumidores ou poss√≠veis consumidores dos conte√∫dos relacionados ao Homem Aranha comentam sobre estes na rede social Twitter. Para classificar a relev√¢ncia dos Twittes observamos os coment√°rios que tinham rela√ß√£o a alguma opini√£o ou sentimento a respeito das obras citadas acima, sejam eles bons ou ruins, todo o resto que destoava muito desses conceitos foi descartado. \n",
    "\n",
    "\n",
    "Exemplos de assuntos considerados relevantes:\n",
    "- Cr√≠ticas ao jogo do Homem Aranha produzido pela Sony.\n",
    "- Coment√°rios de quem foi o melhor ator a interpretar o Homem aranha nos cinemas.\n",
    "- Elogios a alguma cena do filme do personagem.\n",
    "\n",
    "<center><img src=\"aranha.gif\" width=700 style=\"float: center; margin: 0px 0px 10px 10px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import nltk\n",
    "import re\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\caior\\OneDrive\\Faculdade\\2¬∞ PER√çODO\\Ci√™ncia dos Dados\\Projetos\\Homem-Aranha\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Homem-Aranha.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t√°, com \"god of war: ragnarok\", \"homem-aranha ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@flamenguismo_ @venecasagrande os cara se enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assisti venom e amei. agora vou ver todos os f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gabriel71551446 @oswaldooell @n3m_ai @xboxnat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s√©rio mesmo, eu quero muito assistir homem ara...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0  t√°, com \"god of war: ragnarok\", \"homem-aranha ...              0\n",
       "1  @flamenguismo_ @venecasagrande os cara se enco...              0\n",
       "2  assisti venom e amei. agora vou ver todos os f...              1\n",
       "3  @gabriel71551446 @oswaldooell @n3m_ai @xboxnat...              1\n",
       "4  s√©rio mesmo, eu quero muito assistir homem ara...              1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amo homem aranha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@drika_nozes na verdade esse √© o plot de homem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@vicgabil @cinepop falou que vai estrear na me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@goodnerd23 os doisüëç s√≥ n sei como vou aguenta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@cacocardassi homem aranha, √≥bvio!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0                                   amo homem aranha              1\n",
       "1  @drika_nozes na verdade esse √© o plot de homem...              0\n",
       "2  @vicgabil @cinepop falou que vai estrear na me...              0\n",
       "3  @goodnerd23 os doisüëç s√≥ n sei como vou aguenta...              0\n",
       "4                @cacocardassi homem aranha, √≥bvio!!              1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi considerado como relevante todo coment√°rio referente ao universo Homem-Aranha (quadrinhos, filmes e jogos) que expressava opini√µes ou sentimentos, sejam eles bons ou ruins, referente √†s obras, de forma que estes apresentassem algum tipo de embasamento, n√£o sendo considerado como relevante, portanto, coment√°rios desconexos ou pouco pertinentes com a an√°lise cr√≠tica.\n",
    "\n",
    "Passamos pelos seguintes passos de limpeza e manipula√ß√£o dos coment√°rios:\n",
    "* Limpar as pontua√ß√µes e caracteres como \"@\" e '!';\n",
    "* Retirar os paragrafos existentes em alguns coment√°rios;\n",
    "* Dividir as palavras em listas para an√°lise probal√≠stica de cada palavra existentes nos coment√°rios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fun√ß√µes iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirando pontua√ß√µes dos tweets\n",
    "def cleanup(tweet):\n",
    "    punctuation = '[(\\n‚Äù\\-/!.:?;,''\"#)]'             \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern,'', tweet)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\caior\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "prep = nltk.corpus.stopwords.words('portuguese')\n",
    "prep.append('pra')\n",
    "\n",
    "def limpa_preposicao(lista):\n",
    "    sem_prep=[]     \n",
    "    for palavra in lista: \n",
    "        if not palavra in prep: \n",
    "            sem_prep.append(palavra)\n",
    "    return sem_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpa @ e links dos elementos de uma lista\n",
    "def limpa_marcacao(lista):\n",
    "    sem_marc = []\n",
    "    for palavra in limpa_preposicao(lista):\n",
    "        if not 'https' in palavra:\n",
    "            if not '@' in palavra:\n",
    "                sem_marc.append(palavra)\n",
    "        else:\n",
    "            continue\n",
    "    return sem_marc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpa @ e links de uma string\n",
    "def limpa_marcacao1(linha):\n",
    "    sem_marc = []\n",
    "    for palavra in limpa_preposicao(linha.split()):\n",
    "        if not 'https' in palavra:\n",
    "            if not '@' in palavra:\n",
    "                sem_marc.append(palavra)\n",
    "        else:\n",
    "            continue\n",
    "    return sem_marc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa emojis seguidos, e os transcreve\n",
    "def separa_emoji(tweet):\n",
    "    modified=' '.join(emoji.get_emoji_regexp().split(tweet))\n",
    "    modified=modified.split()\n",
    "    for i,emoji1 in enumerate(modified):\n",
    "        if emoji1 in UNICODE_EMOJI['pt']:\n",
    "            modified[i]=UNICODE_EMOJI['pt'][emoji1].replace(':','')\n",
    "        elif emoji1 in UNICODE_EMOJI['en']:\n",
    "            modified[i]=UNICODE_EMOJI['en'][emoji1].replace(':','')\n",
    "        else:\n",
    "            continue\n",
    "    modified=' '.join(modified)  \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica as fun√ß√µes anteriores e retorna uma lista de palavras do dataframe.Treinamento\n",
    "def treinamento(dataframe):\n",
    "    palavras = []\n",
    "    for linha in dataframe.Treinamento:\n",
    "        linha = separa_emoji(cleanup(linha))\n",
    "        for palavra in limpa_marcacao(linha.split()):\n",
    "            palavras.append(palavra)\n",
    "    return palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica as fun√ß√µes anteriores e retorna uma lista de tweets (frases) do dataframe.Treinamento\n",
    "def treinamento1(dataframe):\n",
    "    frases = []\n",
    "    for linha in dataframe.Treinamento:\n",
    "        linha = limpa_marcacao1(separa_emoji(cleanup(linha)))\n",
    "        frases.append(linha)\n",
    "    return frases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Um pouco sobre  o Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretendemos construir um algoritimo que consiga tomar a decis√£o de agrupar uma frase como um assunto relevante ou n√£o relevante sobre o tema ou produto Homem-Aranha. Utilizaremos o Naive Bayes para classificar textos baseado na frequ√™ncia das palavras utilizadas, sendo assim conhecido por ser um classificador probabil√≠stico que utiliza do Teorema de Bayes, visto de maneira mais aprofundada nas aulas de Ci√™ncia dos Dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Probabilidades Iniciais:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente iremos calcular a probabilidade de palavras relevantes e irrelevantes aparecerem em nosso conjunto total:\n",
    "\n",
    "$$ P_{relevante}= \\frac{N¬∞ Palavras_{relevantes}}{N¬∞ Total_{palavras}} $$\n",
    "\n",
    "$$ P_{irrelevante}= \\frac{N¬∞ Palavras_{irrelevantes}}{N¬∞ Total_{palavras}} $$\n",
    "\n",
    "De acordo com a teoria complementar de conjuntos:\n",
    "\n",
    "$$ P_{relevante}+ P_{irrelevante}=1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demais Probabilidades:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(R) \\rightarrow $ Probabilidade de um Tweet ser relevante.\n",
    "\n",
    "$P(I)  \\ ou \\ P(R^c)\\rightarrow$ Probabilidade de um Tweet ser irrelevante.\n",
    "\n",
    "$P(tweet) \\rightarrow$ Probabilidade de determinado Tweet ocorrer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As probabilidades que o nosso classificador precisa encontrar s√£o: \"Dado um tweet, qual a probabilidade dele ser relevante?\" e \"Dado um tweet, qual a probabilidade dele ser irrelevante?\", sendo ambas, respectivamente, representadas por $P(R|tweet)$ e $P(I|tweet)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa maneira, temos que:\n",
    "\n",
    "$$ P(R|tweet)= \\frac{P(tweet \\cap R)}{P(tweet)} $$\n",
    "\n",
    "$$ P(I|tweet)= \\frac{P(tweet \\cap I)}{P(tweet)} $$\n",
    "\n",
    "Sabendo-se que $P(tweet \\cap R)$ e $P(tweet \\cap I)$ tamb√©m podem ser encontrada pelas seguintes rela√ß√µes:\n",
    "\n",
    "$$ P(tweet|R)= \\frac{P(tweet \\cap R)}{P(R)} $$\n",
    "\n",
    "$$ P(tweet|I)= \\frac{P(tweet \\cap I)}{P(I)} $$\n",
    "\n",
    "Obtemos que a probabilidade utilizada por Naive Bayes para classificar um texto como relevante ou n√£o relevante s√£o:\n",
    "\n",
    "$$ P(R|tweet)= \\frac{P(tweet|R) P(R)}{P(tweet)} $$\n",
    "\n",
    "$$ P(I|tweet)= \\frac{P(tweet|I) P(I)}{P(tweet)} $$\n",
    "\n",
    "Como o denominador denotado por $P(tweet)$ aparece em ambas as equa√ß√µes, ele acaba sendo desconsiderado nos c√°lculos comparativos das probabilidades.\n",
    "\n",
    "Por conseguinte, conclui-se que:\n",
    "\n",
    "  $\\quad \\Rightarrow$ Se $P(R|tweet) > P(I|tweet)$, o tweet ser√° classificado como **Relevante**.\n",
    "\n",
    "  $\\quad \\Rightarrow$ Se $P(R|tweet) < P(I|tweet)$, o tweet ser√° classificado como **Irrelevante**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independ√™ncia de palavras - O lado ing√™nuo do classificador:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As probabilidades $P(tweet|R)$ e $P(tweet|I)$ podem ser representadas considerando-se que haja uma independ√™ncia das palavras em um dado tweet. Justamente por esse motivo, o classificador √© considerado ing√™nuo, por desconsiderar a ordena√ß√£o das palavras e analis√°-las de forma independente, de modo que a probabilidade de uma palavra ocorrer na frase n√£o influencia na probabilidade de outra ocorrer\n",
    "\n",
    "$$ P(R|tweet) = \\frac{P(palavra_1|R)P(palavra_2|R)...P(palavra_n|R) P(R)}{P(tweet)}$$\n",
    "\n",
    "$$P(I|tweet)=\\frac{P(palavra_1|I)P(palavra_2|I)...P(palavra_n|I) P(I)}{P(tweet)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suaviza√ß√£o de Laplace:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso de aparecer uma palavra que n√£o esteja na base de dados, precisaremos recorrer √† Suaviza√ß√£o de Laplace, que inclui uma nova palavra nas palavras classificadas como relevantes ou irrelevantes. Para isso, deve-se observar quantas vezes a palavra analisada aparece na compara√ß√£o em quest√£o, seja relevante ou irrelavante, somar uma unidade no numerador evitando o 0, e somar a quantidade representadas pelas poss√≠veis palavras no denominador, isto √© a quantidade de palavras √∫nicas pertencentes aos tweets relevantes ou irrelevantes.\n",
    "\n",
    "Dessarte, ter-se-√° as probabilidades $P(tweet|R)$ e $P(tweet|I)$ adequadas para receber as novas palavras.\n",
    "\n",
    "$$P(palavra1|R) = \\frac{F_{AR}+1}{P_{R}+P_p}$$\n",
    "\n",
    "$$P(palavra1|I) = \\frac{F_{AI}+1}{P_{I}+P_p}$$\n",
    " \n",
    "Sendo: \n",
    "\n",
    "$ F_{AR}$: Frequ√™ncia absoluta da palavra relevante \n",
    "\n",
    "$ F_{AI}$: Frequ√™ncia absoluta da palavra irrelevante \n",
    "    \n",
    "$P_{R}$: Todas as palavras pertencentes aos tweets relevantes\n",
    "    \n",
    "$P_{I}$: Todas as palavras pertencentes aos tweets irrelevantes\n",
    "\n",
    "$P_p$: Todas as palavras poss√≠veis na base de dados de treinamento. Em outrar palavras, esse √© o tamanho do vocabul√°rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets relevantes da planilha de Treinamento\n",
    "train1 = train.loc[train.Classifica√ß√£o == 1]\n",
    "# Tweets irrelevantes da planilha de Treinamento\n",
    "train2 = train.loc[train.Classifica√ß√£o == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series com as palavras da planilha Treinamento\n",
    "palavras_treinamento = pd.Series(treinamento(train))\n",
    "# Series com as palavras relevantes da planilha Treinamento\n",
    "palavras_relevantes = pd.Series(treinamento(train1))\n",
    "# Series com as palavras irrelevantes da planilha Treinamento\n",
    "palavras_irrelevantes = pd.Series(treinamento(train2))\n",
    "# Ocorr√™ncia das palavras da planilha Treinamento\n",
    "planilha_treinamento = palavras_treinamento.value_counts()\n",
    "tamanho_vocabulario = len(planilha_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocorr√™ncia das palavras relevantes da planilha Treinamento\n",
    "relevantes = palavras_relevantes.value_counts()\n",
    "# Ocorr√™ncia das palavras irrelevantes da planilha Treinamento\n",
    "irrelevantes = palavras_irrelevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de palavras sem repeti√ß√µes da planilha Treinamento\n",
    "total = len(relevantes) + len(irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freq. relativa das palavras relevantes da planilha Treinamento\n",
    "relevantes_rel = palavras_relevantes.value_counts(True)\n",
    "# Freq. relativa das palavras irrelevantes da planilha Treinamento\n",
    "irrelevantes_rel = palavras_irrelevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_relevantes = relevantes.sum()\n",
    "total_irrelevantes = irrelevantes.sum()\n",
    "total_palavras = total_relevantes + total_irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets relevantes da planilha de Teste\n",
    "test1 = test.loc[test.Classifica√ß√£o == 1]\n",
    "# Tweets relevantes da planilha de Teste\n",
    "test2 = test.loc[test.Classifica√ß√£o == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica as fun√ß√µes anteriores e retorna uma lista de palavras do dataframe.Teste\n",
    "def teste(dataframe):\n",
    "    palavras = []\n",
    "    for linha in dataframe.Teste:\n",
    "        linha = separa_emoji(cleanup(linha))\n",
    "        for palavra in limpa_marcacao(linha.split()):\n",
    "            palavras.append(palavra)\n",
    "    return palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica as fun√ß√µes anteriores e retorna uma lista de tweets (frases) do dataframe.Teste\n",
    "def teste1(dataframe):\n",
    "    frases = []\n",
    "    for linha in dataframe.Teste:\n",
    "        linha = limpa_marcacao1(separa_emoji(cleanup(linha)))\n",
    "        frases.append(linha)\n",
    "    return frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades iniciais\n",
    "probR = total_relevantes/total_palavras \n",
    "probI = total_irrelevantes/total_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica(dataframe):\n",
    "    '''\n",
    "    Fun√ß√£o que, dada a planilha Teste, ir√° classificar, tweet a tweet, a probabilidade dele ser relevante ou n√£o \n",
    "    '''\n",
    "    algoritmo = []\n",
    "    for frase in teste1(dataframe):\n",
    "        probPalavraDadoR = 1\n",
    "        probPalavraDadoI = 1\n",
    "        for palavra in frase:\n",
    "            if not palavra in relevantes.keys(): # Se a palavra n√£o estiver na lista de relevantes, sua ocorr√™ncia ser√° 0\n",
    "                relevantes[palavra] = 0\n",
    "            if not palavra in irrelevantes.keys(): # Se a palavra n√£o estiver na lista de irrelevantes, sua ocorr√™ncia ser√° 0\n",
    "                irrelevantes[palavra] = 0\n",
    "\n",
    "            probPalavraDadoR *= (relevantes[palavra] + 1)/(total_relevantes + tamanho_vocabulario)\n",
    "            probPalavraDadoI *= (irrelevantes[palavra] + 1)/(total_irrelevantes + tamanho_vocabulario)\n",
    "        \n",
    "        probRDadoPalavra = probPalavraDadoR*probR\n",
    "        probIDadoPalavra = probPalavraDadoI*probI\n",
    "        \n",
    "        if probRDadoPalavra > probIDadoPalavra:\n",
    "            algoritmo.append(1)\n",
    "        else:\n",
    "            algoritmo.append(0)\n",
    "    return algoritmo\n",
    "# Freq. absoluta das palavras de uma tag com repeti√ß√µes\n",
    "# Tamanho do vocabul√°rio: quantidade de palavras considerando as duas tags, sem repeti√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Algoritmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amo homem aranha</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@drika_nozes na verdade esse √© o plot de homem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@vicgabil @cinepop falou que vai estrear na me...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@goodnerd23 os doisüëç s√≥ n sei como vou aguenta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@cacocardassi homem aranha, √≥bvio!!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@racionalxbox @gamerspubbr s√≥ o homem aranha j...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim eu sou vi√∫vo de tobey maguire e andrew gar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@caduaroso pinguim e falcone s√£o mafiosos\\nban...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>toda vez que eu comento num post do dalau q eu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jogo do homem aranha 2 e do wolverine anunciad...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o  Algoritmo\n",
       "0                                   amo homem aranha              1          1\n",
       "1  @drika_nozes na verdade esse √© o plot de homem...              0          0\n",
       "2  @vicgabil @cinepop falou que vai estrear na me...              0          1\n",
       "3  @goodnerd23 os doisüëç s√≥ n sei como vou aguenta...              0          1\n",
       "4                @cacocardassi homem aranha, √≥bvio!!              1          1\n",
       "5  @racionalxbox @gamerspubbr s√≥ o homem aranha j...              1          1\n",
       "6  sim eu sou vi√∫vo de tobey maguire e andrew gar...              1          1\n",
       "7  @caduaroso pinguim e falcone s√£o mafiosos\\nban...              0          0\n",
       "8  toda vez que eu comento num post do dalau q eu...              0          0\n",
       "9  jogo do homem aranha 2 e do wolverine anunciad...              1          1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[:, 'Algoritmo'] = classifica(test)\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Algoritmo</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.5</td>\n",
       "      <td>45.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algoritmo         0     1\n",
       "Classifica√ß√£o            \n",
       "0              15.5  45.5\n",
       "1               5.5  33.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_de_comparacao = pd.crosstab(test[\"Classifica√ß√£o\"] , test[\"Algoritmo\"], normalize=True)*100\n",
    "matriz_de_comparacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia: 49.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Acur√°cia: {0:.2f}%\".format(matriz_de_comparacao[0][0] + matriz_de_comparacao[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O percentual de **verdadeiros positivos** do nosso classificador Naive-Bayes foi de **33,50%**\n",
    "- O percentual de **verdadeiros negativos** do nosso classificador Naive-Bayes foi de **15,50%**\n",
    "- O percentual de **falsos positivos** do nosso classificador Naive-Bayes foi de **45,50%**\n",
    "- O percentual de **falsos negativos** do nosso classificador Naive-Bayes foi de **5,50%**\n",
    "\n",
    "Tendo isso em vista, nosso classificador apresentou uma **acur√°cia** de **49,00%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para efeitos de visualiza√ß√£o, usou-se a pr√≥pria planilha de Treinamento para realizar-se compara√ß√£o da classifica√ß√£o do algoritmo com a feita manualmente, para assegurar que n√£o houve grandes problemas com o c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica(dataframe):\n",
    "    '''\n",
    "    Fun√ß√£o que, dada a planilha Teste, ir√° classificar, tweet a tweet, a probabilidade dele ser relevante ou n√£o \n",
    "    '''\n",
    "    algoritmo = []\n",
    "    for frase in treinamento1(dataframe):\n",
    "        probPalavraDadoR = 1\n",
    "        probPalavraDadoI = 1\n",
    "        for palavra in frase:\n",
    "            if not palavra in relevantes.keys(): # Se a palavra n√£o estiver na lista de relevantes, sua ocorr√™ncia ser√° 0\n",
    "                relevantes[palavra] = 0\n",
    "            if not palavra in irrelevantes.keys(): # Se a palavra n√£o estiver na lista de irrelevantes, sua ocorr√™ncia ser√° 0\n",
    "                irrelevantes[palavra] = 0\n",
    "\n",
    "            probPalavraDadoR *= (relevantes[palavra] + 1)/(total_relevantes + tamanho_vocabulario)\n",
    "            probPalavraDadoI *= (irrelevantes[palavra] + 1)/(total_irrelevantes + tamanho_vocabulario)\n",
    "        \n",
    "        probRDadoPalavra = probPalavraDadoR*probR\n",
    "        probIDadoPalavra = probPalavraDadoI*probI\n",
    "        \n",
    "        if probRDadoPalavra > probIDadoPalavra:\n",
    "            algoritmo.append(1)\n",
    "        else:\n",
    "            algoritmo.append(0)\n",
    "    return algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:, 'Algoritmo'] = classifica(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Algoritmo</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.795987</td>\n",
       "      <td>5.685619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.518395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algoritmo              0          1\n",
       "Classifica√ß√£o                      \n",
       "0              38.795987   5.685619\n",
       "1               0.000000  55.518395"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_de_comparacao = pd.crosstab(train[\"Classifica√ß√£o\"] , train[\"Algoritmo\"], normalize=True)*100\n",
    "matriz_de_comparacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia: 94.31%\n"
     ]
    }
   ],
   "source": [
    "print(\"Acur√°cia: {0:.2f}%\".format(matriz_de_comparacao[0][0] + matriz_de_comparacao[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a acur√°cia, neste testagem, apresentou uma alta porcentagem, de 94,31%, o algoritmo funcionou de acordo com o esperado, podendo-se concluir, portanto, que n√£o houve alguma incoveni√™ncia not√≥ria na maneira como o c√≥digo deste arquivo foi estruturado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo-se em vista os percentuais obtidos com o nosso classificador Naive-Bayes acerca do produto ou tema escolhido, pode-se concluir que este apresentou um funcionamento razo√°vel. Apesar de sua performance n√£o ter sido uma das mais consider√°veis, muitos foram os motivos pelos quais o classificador mostrou um percentual de acur√°cia quase que parcialmente efetivo, de 49,00%.\n",
    "Entre eles, √© preciso considerar-se a exist√™ncia de frases sarc√°sticas ou que apresentam dupla nega√ß√£o, pois, como j√° comentado anteriormente, o classificador constru√≠do com os recursos utilizados √© ing√™nuo, e isso se abrange a esses tipos de frases que podem ser bastante comuns no mundo humano, mas s√£o extremamente complexas para um algoritmo compreender de maneira genuina. Outra quest√£o a ser levantada √© a presen√ßa do cada vez mais comentado vi√©s tecnol√≥gico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O vi√©s na tecnologia: um ponto simples, mas que merece aten√ß√£o! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse dito vi√©s tecnol√≥gico √© mais facilmente compreendido como um comportamento tendencioso que uma dada tecnologia pode apresentar, ou talvez sempre apresente, por um simples motivo: um determinado sistema que faz o uso de um algoritmo, seja um classificador como o nosso, ou uma tecnologia que usufrui de intelig√™ncia artificial, ou um sistema de reconhecimento facial, por exemplo, foi programado por ningu√©m mais, ningu√©m menos que um humano que, por sinal, possui determinadas cren√ßas, percep√ß√µes e uma vis√£o de mundo √∫nicas, de forma que, se esse sistema n√£o for analisado detalhadamente, este pode apresentar um comportamento tendencioso que lhe foi passado atrav√©s dos vieses inconcientes da pessoa por detr√°s dessa feitura. Um exemplo cl√°ssico e que vem chamando muito a aten√ß√£o √© o fato de determinadas tecnologias de reconhecimento facial implementadas por alguns pa√≠ses n√£o reconhecerem facilmente pessoas de cor preta ou, no caso de algoritmos de detec√ß√£o de perfis de risco, acusarem com muito mais incid√™ncia pessoas negras em compara√ß√£o com brancas. \n",
    "\n",
    "Em se tratando do nosso caso, menos grave que os exemplificados acima, a prop√≥sito, como foi comentado que um dos crit√©rios para que um tweet fosse classificado como relevante era ter mensagens acerca de HQs do universo Homem-Aranha, isso, ainda assim, √© algo relativo, pois h√° uma diferen√ßa entre, por exemplo, citar-se apenas um HQ referente ao universo Homem-Aranha e em falar-se de uma maneira com muita propriedade acerca de fatos, personagens, tramas a respeito das obras ficcionais de Homem-Aranha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que  n√£o podemos usar o pr√≥prio classificador para gerar mais amostras de treinamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso algoritmo de Naive Bayes tenta classificar outros tweets com base no que ela aprendeu observando a base de treinamento. Isso condiciona o nosso classificador a classificar sempre baseado na planilha que ele tem acesso e, com isso, ele se torna tendencioso. Para que fosse poss√≠vel gerar mais amostras seria necess√°rio ir atualizando a base de treinamento periodicamente para que o classificador aumente sua base de dados e fique mais preparado para classificar novos tweets de forma mais eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plano de Expans√£o - O Naive Bayes em diferentes contextos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o classificador Naive Bayes presente neste arquivo foi testado em tweets de tamanho similar aos quais ele foi treinado, a partir da base de dados de treinamento, pudemos perceber que ele funcionou de forma razo√°vel. Se consider√°ssemos que ele atuasse com uma base de dados de teste mais sucinta, com cada tweet contendo apenas palavras-chave, √© coerente dizer que a efic√°cia do classificador aumentaria, tendo em vista que este atua com base principalmente nessas palavras-chave mais comuns observadas ap√≥s a limpeza dos tweets. Assim, √© remetida uma situa√ß√£o muito recorrente no cen√°rio atual, no qual as pesquisas, em seu sentido mais amplo, que s√£o realizadas pelas diferentes faixas et√°rias, s√£o tra√ßadas de forma similar, a partir dessas palavras-chave. Dessa forma, o Naive-Bayes seria de grande utilidade para filtrar o que √© mais pesquisado, que passa a ser classificado como relevante, em princ√≠pio, para fazer melhorias nas sugest√µes, seja de sites, v√≠deos, ou se filmes e s√©ries, considerando o uso de plataforma streamings. No entanto, √© claro: para que isso aconte√ßa, ser√£o necess√°rias variadas itera√ß√µes pr√©vias e, dessa forma, ganhar-se-√° cada vez mais notoriedade por impresas interessadas.\n",
    "\n",
    "Outra aplica√ß√£o do classificador seria na filtragem e no reconhecimento da opini√£o do p√∫blico geral a respeito do andamento das obras do universo Homem-Aranha, para que se torne facilitada a captura de informa√ß√µes, possobilitando que haja um embasamento maior e mais r√°pido do que est√° interessante nas obras e deve continuar ocorrendo ou ainda ser melhorada, do que j√° n√£o est√° apresentando mais tanta notoriedade pelo p√∫blico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "No c√≥digo abaixo, tentou-se realizar uma opera√ß√£o para verificar a qualidade do classificador, realizando-se, para isso, novas separa√ß√µes entre a base de Treinamento e Teste. Para isso, foi consultada a documenta√ß√£o da biblioteca sklearn, mas a sua implementa√ß√£o n√£o foi totalmente conclu√≠da."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza(linha):\n",
    "    f = ','.join(limpa_marcacao1(separa_emoji(cleanup(linha)))).replace(',',' ')\n",
    "    return f\n",
    "\n",
    "# Unindo as tabelas em uma\n",
    "test_novo = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test_novo = test_novo.rename(columns={'Teste':'Total'})\n",
    "\n",
    "train_novo = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train_novo = train_novo.rename(columns={'Treinamento':'Total'})\n",
    "\n",
    "# Juntando em um √∫nico dataframe\n",
    "data = pd.concat([train_novo,test_novo])\n",
    "\n",
    "# Limpeza\n",
    "data['Limpo'] = data['Total'].apply(limpeza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, fez-se apenas o mesmo procedimento para algumas vari√°veis tamb√©m presentes no t√≥pico sobre o classificador Naive Bayes, para facilitar a utiliza√ß√£o da fun√ß√£o classifica5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets relevantes da planilha de Teste\n",
    "test1 = test.loc[test.Classifica√ß√£o == 1]\n",
    "# Tweets relevantes da planilha de Teste\n",
    "test2 = test.loc[test.Classifica√ß√£o == 0]\n",
    "\n",
    "# Aplica as fun√ß√µes anteriores e retorna uma lista de palavras do dataframe.Teste\n",
    "def teste(dataframe):\n",
    "    palavras = []\n",
    "    for linha in dataframe.Teste:\n",
    "        linha = separa_emoji(cleanup(linha))\n",
    "        for palavra in limpa_marcacao(linha.split()):\n",
    "            palavras.append(palavra)\n",
    "    return palavras\n",
    "\n",
    "# Aplica as fun√ß√µes anteriores e retorna uma lista de tweets (frases) do dataframe.Teste\n",
    "def teste1(dataframe):\n",
    "    frases = []\n",
    "    for linha in dataframe.Teste:\n",
    "        linha = limpa_marcacao1(separa_emoji(cleanup(linha)))\n",
    "        frases.append(linha)\n",
    "    return frases\n",
    "\n",
    "# Series com as palavras da planilha Teste\n",
    "palavras_test = pd.Series(teste(test))\n",
    "# Series com as palavras relevantes da planilha Teste\n",
    "palavras_relevantes_test = pd.Series(teste(test1))\n",
    "# Series com as palavras irrelevantes da planilha Teste\n",
    "palavras_irrelevantes_test = pd.Series(teste(test2))\n",
    "# Ocorr√™ncia das palavras da planilha Teste\n",
    "planilha_teste = palavras_test.value_counts()\n",
    "\n",
    "# Ocorr√™ncia das palavras relevantes da planilha Teste\n",
    "relevantes_test = palavras_relevantes_test.value_counts()\n",
    "# Ocorr√™ncia das palavras irrelevantes da planilha Teste\n",
    "irrelevantes_test = palavras_irrelevantes_test.value_counts()\n",
    "\n",
    "total_test = len(relevantes_test) + len(irrelevantes_test)\n",
    "\n",
    "probR = total_relevantes/total_palavras \n",
    "probI = total_irrelevantes/total_palavras\n",
    "\n",
    "def classifica5(dataframe, relevantes, irrelevantes, total_relevantes, total_irrelevantes, tamanho_vocabulario):\n",
    "    '''\n",
    "    Fun√ß√£o que, dada a planilha Teste, ir√° classificar, tweet a tweet, a probabilidade dele ser relevante ou n√£o \n",
    "    '''\n",
    "    algoritmo = []\n",
    "    for frase in dataframe:\n",
    "        probPalavraDadoR = 1\n",
    "        probPalavraDadoI = 1\n",
    "        for palavra in frase:\n",
    "            if not palavra in relevantes.keys(): # Se a palavra n√£o estiver na lista de relevantes, sua ocorr√™ncia ser√° 0\n",
    "                relevantes[palavra] = 0\n",
    "            if not palavra in irrelevantes.keys(): # Se a palavra n√£o estiver na lista de irrelevantes, sua ocorr√™ncia ser√° 0\n",
    "                irrelevantes[palavra] = 0\n",
    "\n",
    "            probPalavraDadoR *= (relevantes[palavra] + 1)/(total_relevantes + tamanho_vocabulario)\n",
    "            probPalavraDadoI *= (irrelevantes[palavra] + 1)/(total_irrelevantes + tamanho_vocabulario)\n",
    "        \n",
    "        probRDadoPalavra = probPalavraDadoR*probR\n",
    "        probIDadoPalavra = probPalavraDadoI*probI\n",
    "        \n",
    "        if probRDadoPalavra > probIDadoPalavra:\n",
    "            algoritmo.append(1)\n",
    "        else:\n",
    "            algoritmo.append(0)\n",
    "    return algoritmo\n",
    "\n",
    "# print(classifica(test))\n",
    "# Freq. absoluta das palavras de uma tag com repeti√ß√µes\n",
    "# Tamanho do vocabul√°rio: quantidade de palavras considerando as duas tags, sem repeti√ß√µes\n",
    "\n",
    "# Tweets relevantes da planilha de Treinamento\n",
    "train1 = train.loc[train.Classifica√ß√£o == 1]\n",
    "# Tweets irrelevantes da planilha de Treinamento\n",
    "train2 = train.loc[train.Classifica√ß√£o == 0]\n",
    "\n",
    "# Series com as palavras da planilha Treinamento\n",
    "palavras_treinamento = pd.Series(treinamento(train))\n",
    "# Series com as palavras relevantes da planilha Treinamento\n",
    "palavras_relevantes = pd.Series(treinamento(train1))\n",
    "# Series com as palavras irrelevantes da planilha Treinamento\n",
    "palavras_irrelevantes = pd.Series(treinamento(train2))\n",
    "# Ocorr√™ncia das palavras da planilha Treinamento\n",
    "planilha_treinamento = palavras_treinamento.value_counts()\n",
    "tamanho_vocabulario = len(planilha_treinamento)\n",
    "\n",
    "# Ocorr√™ncia das palavras relevantes da planilha Treinamento\n",
    "relevantes = palavras_relevantes.value_counts()\n",
    "# Ocorr√™ncia das palavras irrelevantes da planilha Treinamento\n",
    "irrelevantes = palavras_irrelevantes.value_counts()\n",
    "\n",
    "# Quantidade de palavras sem repeti√ß√µes da planilha Treinamento\n",
    "total = len(relevantes) + len(irrelevantes)\n",
    "\n",
    "# Freq. relativa das palavras relevantes da planilha Treinamento\n",
    "relevantes_rel = palavras_relevantes.value_counts(True)\n",
    "# Freq. relativa das palavras irrelevantes da planilha Treinamento\n",
    "irrelevantes_rel = palavras_irrelevantes.value_counts(True)\n",
    "\n",
    "total_relevantes = relevantes.sum()\n",
    "total_irrelevantes = irrelevantes.sum()\n",
    "total_palavras = total_relevantes + total_irrelevantes\n",
    "\n",
    "# Aplica as fun√ß√µes anteriores e retorna uma lista de palavras do dataframe.Treinamento\n",
    "def treinamento5(dataframe):\n",
    "    palavras = []\n",
    "    for linha in dataframe.Limpo:\n",
    "        for palavra in linha:\n",
    "            palavras.append(palavra)\n",
    "    return palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, abaixo, por algum motivo, provavelmente pequeno, n√£o foi poss√≠vel realizar as repeti√ß√µes das separa√ß√µes dos tweets. Portanto, n√£o foi impresso, posteriormente, os novos valores de acur√°cia e o gr√°fico histograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# vdd_positivo = []\n",
    "# vdd_negativo = [] \n",
    "# precisao      = []\n",
    "\n",
    "# for i in range(0,10000):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(data[['Limpo','Classifica√ß√£o']],data['Classifica√ß√£o'], test_size=0.4)\n",
    "    \n",
    "#     print(X_train)\n",
    "#     train1 = X_train[X_train['Classifica√ß√£o'] == 1]\n",
    "#     train2 = X_train[X_train['Classifica√ß√£o'] == 0]\n",
    "    \n",
    "#     palavras_treinamento = pd.Series(treinamento5(X_train))\n",
    "    \n",
    "#     palavras_relevantes = pd.Series(treinamento5(train1))\n",
    "#     palavras_irrelevantes = pd.Series(treinamento5(train2))\n",
    "#     planilha_treinamento = palavras_treinamento.value_counts()\n",
    "#     tamanho_vocabulario = len(planilha_treinamento)\n",
    "    \n",
    "#     relevantes = palavras_relevantes.value_counts()\n",
    "#     irrelevantes = palavras_irrelevantes.value_counts()\n",
    "    \n",
    "#     total = len(relevantes) + len(irrelevantes)\n",
    "#     total # DUVIDA: len(palavras_treinamento)\n",
    "\n",
    "#     relevantes_rel = palavras_relevantes.value_counts(True)\n",
    "#     irrelevantes_rel = palavras_irrelevantes.value_counts(True)\n",
    "\n",
    "#     total_relevantes = relevantes.sum()\n",
    "#     total_irrelevantes = irrelevantes.sum()\n",
    "#     total_palavras = total_relevantes + total_irrelevantes\n",
    "    \n",
    "#     probR = total_relevantes/total_palavras \n",
    "#     probI = total_irrelevantes/total_palavras\n",
    "\n",
    "#     X_test.loc[:, 'Classifica√ß√£o'] = classifica5(X_test.Limpo, relevantes, irrelevantes, total_relevantes, total_irrelevantes, tamanho_vocabulario)\n",
    "\n",
    "#     verdadeiro_positivo=X_test.loc[(X_test['Classifica√ß√£o']==1)&(X_test['Classifica√ß√£o']==1),:].shape[0]\n",
    "#     verdadeiro_negativo=X_test.loc[(X_test['Classifica√ß√£o']==0)&(X_test['Classifica√ß√£o']==0),:].shape[0]\n",
    "#     acuracia=(verdadeiro_positivo+verdadeiro_negativo)/X_test.shape[0]\n",
    "    \n",
    "#     P_ver_pos = (verdadeiro_positivo/X_test.shape[0])*100\n",
    "#     P_ver_neg = (verdadeiro_negativo/X_test.shape[0])*100\n",
    "#     acuracia *= 100\n",
    "    \n",
    "#     vdd_positivo.append(P_ver_pos)\n",
    "#     vdd_negativo.append(P_ver_neg)\n",
    "#     precisao.append(acuracia)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
