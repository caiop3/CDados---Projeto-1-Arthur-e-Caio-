{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Arthur Pansini\n",
    "\n",
    "Nome: Caio Ribeiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualiza√ß√£o\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tema escolhido para a realiza√ß√£o desse projeto foi o super her√≥i Homem Aranha, personagem que possui uma franquia de jogos vinculados a empresa Sony, al√©m de uma s√©rie de obras cinematogr√°ficas produzidas pela Marvel Studios.\n",
    "\n",
    "O objetivo que almejamos com o projeto √© de analisar o que os consumidores ou poss√≠veis consumidores dos conte√∫dos relacionados ao Homem Aranha comentam sobre estes na rede social Twitter. Para classificar a relev√¢ncia dos Twittes observamos os coment√°rios que tinham rela√ß√£o a alguma opini√£o ou sentimento a respeito das obras citadas acima, sejam eles bons ou ruins, todo o resto que destoava muito desses conceitos foi descartado. \n",
    "\n",
    "\n",
    "Exemplos de assuntos considerados relevantes:\n",
    "- Cr√≠ticas ao jogo do Homem Aranha produzido pela Sony.\n",
    "- Coment√°rios de quem foi o melhor ator a interpretar o Homem aranha nos cinemas.\n",
    "- Elogios a alguma cena do filme do personagem.\n",
    "\n",
    "<center><img src=\"aranha.gif\" width=700 style=\"float: center; margin: 0px 0px 10px 10px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import nltk\n",
    "import re\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\caior\\OneDrive\\Faculdade\\2¬∞ PER√çODO\\Ci√™ncia dos Dados\\Projetos\\Homem-Aranha\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Homem-Aranha.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t√°, com \"god of war: ragnarok\", \"homem-aranha ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@flamenguismo_ @venecasagrande os cara se enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assisti venom e amei. agora vou ver todos os f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gabriel71551446 @oswaldooell @n3m_ai @xboxnat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s√©rio mesmo, eu quero muito assistir homem ara...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0  t√°, com \"god of war: ragnarok\", \"homem-aranha ...              0\n",
       "1  @flamenguismo_ @venecasagrande os cara se enco...              0\n",
       "2  assisti venom e amei. agora vou ver todos os f...              1\n",
       "3  @gabriel71551446 @oswaldooell @n3m_ai @xboxnat...              1\n",
       "4  s√©rio mesmo, eu quero muito assistir homem ara...              1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amo homem aranha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@drika_nozes na verdade esse √© o plot de homem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@vicgabil @cinepop falou que vai estrear na me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@goodnerd23 os doisüëç s√≥ n sei como vou aguenta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@cacocardassi homem aranha, √≥bvio!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0                                   amo homem aranha              1\n",
       "1  @drika_nozes na verdade esse √© o plot de homem...              0\n",
       "2  @vicgabil @cinepop falou que vai estrear na me...              0\n",
       "3  @goodnerd23 os doisüëç s√≥ n sei como vou aguenta...              0\n",
       "4                @cacocardassi homem aranha, √≥bvio!!              1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi considerado como relevante todo coment√°rio referente ao universo Homem-Aranha (quadrinhos, filmes e jogos) que expressava opini√µes ou sentimentos, sejam eles bons ou ruins, referente √†s obras, de forma que estes apresentassem algum tipo de embasamento, n√£o sendo considerado como relevante, portanto, coment√°rios desconexos ou pouco pertinentes com a an√°lise cr√≠tica.\n",
    "\n",
    "Passamos pelos seguintes passos de limpeza e manipula√ß√£o dos coment√°rios:\n",
    "* Limpar as pontua√ß√µes e caracteres como \"@\" e '!';\n",
    "* Retirar os paragrafos existentes em alguns coment√°rios;\n",
    "* Dividir as palavras em listas para an√°lise probal√≠stica de cada palavra existentes nos coment√°rios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fun√ß√µes iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirando pontua√ß√µes dos tweets\n",
    "def cleanup(tweet):\n",
    "    punctuation = '[(\\n‚Äù\\-/!.:?;,''\"#)]'             \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern,'', tweet)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\caior\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "prep = nltk.corpus.stopwords.words('portuguese')\n",
    "prep.append('pra')\n",
    "\n",
    "def limpa_preposicao(lista):\n",
    "    sem_prep=[]     \n",
    "    for palavra in lista: \n",
    "        if not palavra in prep: \n",
    "            sem_prep.append(palavra)\n",
    "    return sem_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpa @ e links dos elementos de uma lista\n",
    "def limpa_marcacao(lista):\n",
    "    sem_marc = []\n",
    "    for palavra in limpa_preposicao(lista):\n",
    "        if not 'https' in palavra:\n",
    "            if not '@' in palavra:\n",
    "                sem_marc.append(palavra)\n",
    "        else:\n",
    "            continue\n",
    "    return sem_marc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpa @ e links de uma string\n",
    "def limpa_marcacao1(linha):\n",
    "    sem_marc = []\n",
    "    for palavra in limpa_preposicao(linha.split()):\n",
    "        if not 'https' in palavra:\n",
    "            if not '@' in palavra:\n",
    "                sem_marc.append(palavra)\n",
    "        else:\n",
    "            continue\n",
    "    return sem_marc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa emojis seguidos, e os transcreve\n",
    "def separa_emoji(tweet):\n",
    "    modified=' '.join(emoji.get_emoji_regexp().split(tweet))\n",
    "    modified=modified.split()\n",
    "    for i,emoji1 in enumerate(modified):\n",
    "        if emoji1 in UNICODE_EMOJI['pt']:\n",
    "            modified[i]=UNICODE_EMOJI['pt'][emoji1].replace(':','')\n",
    "        elif emoji1 in UNICODE_EMOJI['en']:\n",
    "            modified[i]=UNICODE_EMOJI['en'][emoji1].replace(':','')\n",
    "        else:\n",
    "            continue\n",
    "    modified=' '.join(modified)  \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica as fun√ß√µes anteriores e retorna uma lista de palavras do dataframe.Treinamento\n",
    "def treinamento(dataframe):\n",
    "    palavras = []\n",
    "    for linha in dataframe.Treinamento:\n",
    "        linha = separa_emoji(cleanup(linha))\n",
    "        for palavra in limpa_marcacao(linha.split()):\n",
    "            palavras.append(palavra)\n",
    "    return palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica as fun√ß√µes anteriores e retorna uma lista de tweets (frases) do dataframe.Treinamento\n",
    "def treinamento1(dataframe):\n",
    "    frases = []\n",
    "    for linha in dataframe.Treinamento:\n",
    "        linha = limpa_marcacao1(separa_emoji(cleanup(linha)))\n",
    "        frases.append(linha)\n",
    "    return frases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Um pouco sobre  o Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretendemos construir um algoritimo que consiga tomar a decis√£o de agrupar uma frase como um assunto relevante ou n√£o relevante sobre o tema ou produto Homem-Aranha. Utilizaremos o Naive Bayes para classificar textos baseado na frequ√™ncia das palavras utilizadas, sendo assim conhecido por ser um classificador probabil√≠stico que utiliza do Teorema de Bayes, visto de maneira mais aprofundada nas aulas de Ci√™ncia dos Dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Probabilidades Iniciais:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente iremos calcular a probabilidade de palavras relevantes e irrelevantes aparecerem em nosso conjunto total:\n",
    "\n",
    "$$ P_{relevante}= \\frac{N¬∞ Palavras_{relevantes}}{N¬∞ Total_{palavras}} $$\n",
    "\n",
    "$$ P_{irrelevante}= \\frac{N¬∞ Palavras_{irrelevantes}}{N¬∞ Total_{palavras}} $$\n",
    "\n",
    "De acordo com a teoria complementar de conjuntos:\n",
    "\n",
    "$$ P_{relevante}+ P_{irrelevante}=1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demais Probabilidades:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(R) \\rightarrow $ Probabilidade de um Tweet ser relevante.\n",
    "\n",
    "$P(I)  \\ ou \\ P(R^c)\\rightarrow$ Probabilidade de um Tweet ser irrelevante.\n",
    "\n",
    "$P(tweet) \\rightarrow$ Probabilidade de determinado Tweet ocorrer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As probabilidades que o nosso classificador precisa encontrar s√£o: \"Dado um tweet, qual a probabilidade dele ser relevante?\" e \"Dado um tweet, qual a probabilidade dele ser irrelevante?\", sendo ambas, respectivamente, representadas por $P(R|tweet)$ e $P(I|tweet)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa maneira, temos que:\n",
    "\n",
    "$$ P(R|tweet)= \\frac{P(tweet \\cap R)}{P(tweet)} $$\n",
    "\n",
    "$$ P(I|tweet)= \\frac{P(tweet \\cap I)}{P(tweet)} $$\n",
    "\n",
    "Sabendo-se que $P(tweet \\cap R)$ e $P(tweet \\cap I)$ tamb√©m podem ser encontrada pelas seguintes rela√ß√µes:\n",
    "\n",
    "$$ P(tweet|R)= \\frac{P(tweet \\cap R)}{P(R)} $$\n",
    "\n",
    "$$ P(tweet|I)= \\frac{P(tweet \\cap I)}{P(I)} $$\n",
    "\n",
    "Obtemos que a probabilidade utilizada por Naive Bayes para classificar um texto como relevante ou n√£o relevante s√£o:\n",
    "\n",
    "$$ P(R|tweet)= \\frac{P(tweet|R) P(R)}{P(tweet)} $$\n",
    "\n",
    "$$ P(I|tweet)= \\frac{P(tweet|I) P(I)}{P(tweet)} $$\n",
    "\n",
    "Como o denominador denotado por $P(tweet)$ aparece em ambas as equa√ß√µes, ele acaba sendo desconsiderado nos c√°lculos comparativos das probabilidades.\n",
    "\n",
    "Por conseguinte, conclui-se que:\n",
    "\n",
    "  $\\quad \\Rightarrow$ Se $P(R|tweet) > P(I|tweet)$, o tweet ser√° classificado como **Relevante**.\n",
    "\n",
    "  $\\quad \\Rightarrow$ Se $P(R|tweet) < P(I|tweet)$, o tweet ser√° classificado como **Irrelevante**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independ√™ncia de palavras - O lado ing√™nuo do classificador:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As probabilidades $P(tweet|R)$ e $P(tweet|I)$ podem ser representadas considerando-se que haja uma independ√™ncia das palavras em um dado tweet. Justamente por esse motivo, o classificador √© considerado ing√™nuo, por desconsiderar a ordena√ß√£o das palavras e analis√°-las de forma independente, de modo que a probabilidade de uma palavra ocorrer na frase n√£o influencia na probabilidade de outra ocorrer\n",
    "\n",
    "$$ P(R|tweet) = \\frac{P(palavra_1|R)P(palavra_2|R)...P(palavra_n|R) P(R)}{P(tweet)}$$\n",
    "\n",
    "$$P(I|tweet)=\\frac{P(palavra_1|I)P(palavra_2|I)...P(palavra_n|I) P(I)}{P(tweet)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suaviza√ß√£o de Laplace:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso de aparecer uma palavra que n√£o esteja na base de dados, precisaremos recorrer √† Suaviza√ß√£o de Laplace, que inclui uma nova palavra nas palavras classificadas como relevantes ou irrelevantes. Para isso, deve-se observar quantas vezes a palavra analisada aparece na compara√ß√£o em quest√£o, seja relevante ou irrelavante, somar uma unidade no numerador evitando o 0, e somar a quantidade representadas pelas poss√≠veis palavras no denominador, isto √© a quantidade de palavras √∫nicas pertencentes aos tweets relevantes ou irrelevantes.\n",
    "\n",
    "Dessarte, ter-se-√° as probabilidades $P(tweet|R)$ e $P(tweet|I)$ adequadas para receber as novas palavras.\n",
    "\n",
    "$$P(palavra1|R) = \\frac{F_{AR}+1}{P_{R}+P_p}$$\n",
    "\n",
    "$$P(palavra1|I) = \\frac{F_{AI}+1}{P_{I}+P_p}$$\n",
    " \n",
    "Sendo: \n",
    "\n",
    "$ F_{AR}$: Frequ√™ncia absoluta da palavra relevante \n",
    "\n",
    "$ F_{AI}$: Frequ√™ncia absoluta da palavra irrelevante \n",
    "    \n",
    "$P_{R}$: Todas as palavras pertencentes aos tweets relevantes\n",
    "    \n",
    "$P_{I}$: Todas as palavras pertencentes aos tweets irrelevantes\n",
    "\n",
    "$P_p$: Todas as palavras poss√≠veis na base de dados de treinamento. Em outrar palavras, esse √© o tamanho do vocabul√°rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets relevantes da planilha de Treinamento\n",
    "train1 = train.loc[train.Classifica√ß√£o == 1]\n",
    "# Tweets irrelevantes da planilha de Treinamento\n",
    "train2 = train.loc[train.Classifica√ß√£o == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series com as palavras da planilha Treinamento\n",
    "palavras_treinamento = pd.Series(treinamento(train))\n",
    "# Series com as palavras relevantes da planilha Treinamento\n",
    "palavras_relevantes = pd.Series(treinamento(train1))\n",
    "# Series com as palavras irrelevantes da planilha Treinamento\n",
    "palavras_irrelevantes = pd.Series(treinamento(train2))\n",
    "# Ocorr√™ncia das palavras da planilha Treinamento\n",
    "planilha_treinamento = palavras_treinamento.value_counts()\n",
    "tamanho_vocabulario = len(planilha_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocorr√™ncia das palavras relevantes da planilha Treinamento\n",
    "relevantes = palavras_relevantes.value_counts()\n",
    "# Ocorr√™ncia das palavras irrelevantes da planilha Treinamento\n",
    "irrelevantes = palavras_irrelevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de palavras sem repeti√ß√µes da planilha Treinamento\n",
    "total = len(relevantes) + len(irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freq. relativa das palavras relevantes da planilha Treinamento\n",
    "# relevantes_rel = palavras_relevantes.value_counts(True)\n",
    "# # Freq. relativa das palavras irrelevantes da planilha Treinamento\n",
    "# irrelevantes_rel = palavras_irrelevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_relevantes = relevantes.sum()\n",
    "total_irrelevantes = irrelevantes.sum()\n",
    "total_palavras = total_relevantes + total_irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets relevantes da planilha de Teste\n",
    "test1 = test.loc[test.Classifica√ß√£o == 1]\n",
    "# Tweets relevantes da planilha de Teste\n",
    "test2 = test.loc[test.Classifica√ß√£o == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica as fun√ß√µes anteriores e retorna uma lista de palavras do dataframe.Teste\n",
    "def teste(dataframe):\n",
    "    palavras = []\n",
    "    for linha in dataframe.Teste:\n",
    "        linha = separa_emoji(cleanup(linha))\n",
    "        for palavra in limpa_marcacao(linha.split()):\n",
    "            palavras.append(palavra)\n",
    "    return palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica as fun√ß√µes anteriores e retorna uma lista de tweets (frases) do dataframe.Teste\n",
    "def teste1(dataframe):\n",
    "    frases = []\n",
    "    for linha in dataframe.Teste:\n",
    "        linha = limpa_marcacao1(separa_emoji(cleanup(linha)))\n",
    "        frases.append(linha)\n",
    "    return frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades iniciais\n",
    "probR = total_relevantes/total_palavras \n",
    "probI = total_irrelevantes/total_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica(dataframe):\n",
    "    '''\n",
    "    Fun√ß√£o que, dada a planilha Teste, ir√° classificar, tweet a tweet, a probabilidade dele ser relevante ou n√£o \n",
    "    '''\n",
    "    algoritmo = []\n",
    "    for frase in teste1(dataframe):\n",
    "        probPalavraDadoR = 1\n",
    "        probPalavraDadoI = 1\n",
    "        for palavra in frase:\n",
    "            if not palavra in relevantes.keys(): # Se a palavra n√£o estiver na lista de relevantes, sua ocorr√™ncia ser√° 0\n",
    "                relevantes[palavra] = 0\n",
    "            if not palavra in irrelevantes.keys(): # Se a palavra n√£o estiver na lista de irrelevantes, sua ocorr√™ncia ser√° 0\n",
    "                irrelevantes[palavra] = 0\n",
    "\n",
    "            probPalavraDadoR *= (relevantes[palavra] + 1)/(total_relevantes + tamanho_vocabulario)\n",
    "            probPalavraDadoI *= (irrelevantes[palavra] + 1)/(total_irrelevantes + tamanho_vocabulario)\n",
    "        \n",
    "        probRDadoPalavra = probPalavraDadoR*probR\n",
    "        probIDadoPalavra = probPalavraDadoI*probI\n",
    "        \n",
    "        if probRDadoPalavra > probIDadoPalavra:\n",
    "            algoritmo.append(1)\n",
    "        else:\n",
    "            algoritmo.append(0)\n",
    "    return algoritmo\n",
    "# Freq. absoluta das palavras de uma tag com repeti√ß√µes\n",
    "# Tamanho do vocabul√°rio: quantidade de palavras considerando as duas tags, sem repeti√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Algoritmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amo homem aranha</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@drika_nozes na verdade esse √© o plot de homem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@vicgabil @cinepop falou que vai estrear na me...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@goodnerd23 os doisüëç s√≥ n sei como vou aguenta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@cacocardassi homem aranha, √≥bvio!!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@racionalxbox @gamerspubbr s√≥ o homem aranha j...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim eu sou vi√∫vo de tobey maguire e andrew gar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@caduaroso pinguim e falcone s√£o mafiosos\\nban...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>toda vez que eu comento num post do dalau q eu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jogo do homem aranha 2 e do wolverine anunciad...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o  Algoritmo\n",
       "0                                   amo homem aranha              1          1\n",
       "1  @drika_nozes na verdade esse √© o plot de homem...              0          0\n",
       "2  @vicgabil @cinepop falou que vai estrear na me...              0          1\n",
       "3  @goodnerd23 os doisüëç s√≥ n sei como vou aguenta...              0          1\n",
       "4                @cacocardassi homem aranha, √≥bvio!!              1          1\n",
       "5  @racionalxbox @gamerspubbr s√≥ o homem aranha j...              1          1\n",
       "6  sim eu sou vi√∫vo de tobey maguire e andrew gar...              1          1\n",
       "7  @caduaroso pinguim e falcone s√£o mafiosos\\nban...              0          0\n",
       "8  toda vez que eu comento num post do dalau q eu...              0          0\n",
       "9  jogo do homem aranha 2 e do wolverine anunciad...              1          1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[:, 'Algoritmo'] = classifica(test)\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Algoritmo</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.5</td>\n",
       "      <td>45.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algoritmo         0     1\n",
       "Classifica√ß√£o            \n",
       "0              15.5  45.5\n",
       "1               5.5  33.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_de_comparacao = pd.crosstab(test[\"Classifica√ß√£o\"] , test[\"Algoritmo\"], normalize=True)*100\n",
    "matriz_de_comparacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia: 49.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Acur√°cia: {0:.2f}%\".format(matriz_de_comparacao[0][0] + matriz_de_comparacao[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O percentual de **verdadeiros positivos** do nosso classificador Naive-Bayes foi de **33,50%**\n",
    "- O percentual de **verdadeiros negativos** do nosso classificador Naive-Bayes foi de **15,50%**\n",
    "- O percentual de **falsos positivos** do nosso classificador Naive-Bayes foi de **45,50%**\n",
    "- O percentual de **falsos negativos** do nosso classificador Naive-Bayes foi de **5,50%**\n",
    "\n",
    "Tendo isso em vista, nosso classificador apresentou uma **acur√°cia** de **49,00%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para efeitos de visualiza√ß√£o, usou-se a pr√≥pria planilha de Treinamento para realizar-se compara√ß√£o da classifica√ß√£o do algoritmo com a feita manualmente, para assegurar que n√£o houve grandes problemas com o c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica(dataframe):\n",
    "    '''\n",
    "    Fun√ß√£o que, dada a planilha Teste, ir√° classificar, tweet a tweet, a probabilidade dele ser relevante ou n√£o \n",
    "    '''\n",
    "    algoritmo = []\n",
    "    for frase in treinamento1(dataframe):\n",
    "        probPalavraDadoR = 1\n",
    "        probPalavraDadoI = 1\n",
    "        for palavra in frase:\n",
    "            if not palavra in relevantes.keys(): # Se a palavra n√£o estiver na lista de relevantes, sua ocorr√™ncia ser√° 0\n",
    "                relevantes[palavra] = 0\n",
    "            if not palavra in irrelevantes.keys(): # Se a palavra n√£o estiver na lista de irrelevantes, sua ocorr√™ncia ser√° 0\n",
    "                irrelevantes[palavra] = 0\n",
    "\n",
    "            probPalavraDadoR *= (relevantes[palavra] + 1)/(total_relevantes + tamanho_vocabulario)\n",
    "            probPalavraDadoI *= (irrelevantes[palavra] + 1)/(total_irrelevantes + tamanho_vocabulario)\n",
    "        \n",
    "        probRDadoPalavra = probPalavraDadoR*probR\n",
    "        probIDadoPalavra = probPalavraDadoI*probI\n",
    "        \n",
    "        if probRDadoPalavra > probIDadoPalavra:\n",
    "            algoritmo.append(1)\n",
    "        else:\n",
    "            algoritmo.append(0)\n",
    "    return algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:, 'Algoritmo'] = classifica(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Algoritmo</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.795987</td>\n",
       "      <td>5.685619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.518395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algoritmo              0          1\n",
       "Classifica√ß√£o                      \n",
       "0              38.795987   5.685619\n",
       "1               0.000000  55.518395"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_de_comparacao = pd.crosstab(train[\"Classifica√ß√£o\"] , train[\"Algoritmo\"], normalize=True)*100\n",
    "matriz_de_comparacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia: 94.31%\n"
     ]
    }
   ],
   "source": [
    "print(\"Acur√°cia: {0:.2f}%\".format(matriz_de_comparacao[0][0] + matriz_de_comparacao[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a acur√°cia, neste testagem, apresentou uma alta porcentagem, de 94,31%, o algoritmo funcionou de acordo com o esperado, podendo-se concluir, portanto, que n√£o houve alguma incoveni√™ncia not√≥ria na maneira como o c√≥digo deste arquivo foi estruturado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo-se em vista os percentuais obtidos com o nosso classificador Naive-Bayes acerca do produto ou tema escolhido, pode-se concluir que este apresentou um funcionamento razo√°vel. Apesar de sua performance n√£o ter sido uma das mais consider√°veis, muitos foram os motivos pelos quais o classificador mostrou um percentual de acur√°cia quase que parcialmente efetivo, de 49,00%.\n",
    "Entre eles, √© preciso considerar-se a exist√™ncia de frases sarc√°sticas ou que apresentam dupla nega√ß√£o, pois, como j√° comentado anteriormente, o classificador constru√≠do com os recursos utilizados √© ing√™nuo, e isso se abrange a esses tipos de frases que podem ser bastante comuns no mundo humano, mas s√£o extremamente complexas para um algoritmo compreender de maneira genuina. Outra quest√£o a ser levantada √© a presen√ßa do cada vez mais comentado vi√©s tecnol√≥gico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O vi√©s na tecnologia: um ponto simples, mas que merece aten√ß√£o! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse dito vi√©s tecnol√≥gico √© mais facilmente compreendido como um comportamento tendencioso que uma dada tecnologia pode apresentar, ou talvez sempre apresente, por um simples motivo: um determinado sistema que faz o uso de um algoritmo, seja um classificador como o nosso, ou uma tecnologia que usufrui de intelig√™ncia artificial, ou um sistema de reconhecimento facial, por exemplo, foi programado por ningu√©m mais, ningu√©m menos que um humano que, por sinal, possui determinadas cren√ßas, percep√ß√µes e uma vis√£o de mundo √∫nicas, de forma que, se esse sistema n√£o for analisado detalhadamente, este pode apresentar um comportamento tendencioso que lhe foi passado atrav√©s dos vieses inconcientes da pessoa por detr√°s dessa feitura. Um exemplo cl√°ssico e que vem chamando muito a aten√ß√£o √© o fato de determinadas tecnologias de reconhecimento facial implementadas por alguns pa√≠ses n√£o reconhecerem facilmente pessoas de cor preta ou, no caso de algoritmos de detec√ß√£o de perfis de risco, acusarem com muito mais incid√™ncia pessoas negras em compara√ß√£o com brancas. \n",
    "\n",
    "Em se tratando do nosso caso, menos grave que os exemplificados acima, a prop√≥sito, como foi comentado que um dos crit√©rios para que um tweet fosse classificado como relevante era ter mensagens acerca de HQs do universo Homem-Aranha, isso, ainda assim, √© algo relativo, pois h√° uma diferen√ßa entre, por exemplo, citar-se apenas um HQ referente ao universo Homem-Aranha e em falar-se de uma maneira com muita propriedade acerca de fatos, personagens, tramas a respeito das obras ficcionais de Homem-Aranha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que  n√£o podemos usar o pr√≥prio classificador para gerar mais amostras de treinamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso algoritmo de Naive Bayes tenta classificar outros tweets com base no que ela aprendeu observando a base de treinamento. Isso condiciona o nosso classificador a classificar sempre baseado na planilha que ele tem acesso e, com isso, ele se torna tendencioso. Para que fosse poss√≠vel gerar mais amostras seria necess√°rio ir atualizando a base de treinamento periodicamente para que o classificador aumente sua base de dados e fique mais preparado para classificar novos tweets de forma mais eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plano de Expans√£o - O Naive Bayes em diferentes contextos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o classificador Naive Bayes presente neste arquivo foi testado em tweets de tamanho similar aos quais ele foi treinado, a partir da base de dados de treinamento, pudemos perceber que ele funcionou de forma razo√°vel. Se consider√°ssemos que ele atuasse com uma base de dados de teste mais sucinta, com cada tweet contendo apenas palavras-chave, √© coerente dizer que a efic√°cia do classificador aumentaria, tendo em vista que este atua com base principalmente nessas palavras-chave mais comuns observadas ap√≥s a limpeza dos tweets. Assim, √© remetida uma situa√ß√£o muito recorrente no cen√°rio atual, no qual as pesquisas, em seu sentido mais amplo, que s√£o realizadas pelas diferentes faixas et√°rias, s√£o tra√ßadas de forma similar, a partir dessas palavras-chave. Dessa forma, o Naive-Bayes seria de grande utilidade para filtrar o que √© mais pesquisado, que passa a ser classificado como relevante, em princ√≠pio, para fazer melhorias nas sugest√µes, seja de sites, v√≠deos, ou se filmes e s√©ries, considerando o uso de plataforma streamings. No entanto, √© claro: para que isso aconte√ßa, ser√£o necess√°rias variadas itera√ß√µes pr√©vias e, dessa forma, ganhar-se-√° cada vez mais notoriedade por impresas interessadas.\n",
    "\n",
    "Outra aplica√ß√£o do classificador seria na filtragem e no reconhecimento da opini√£o do p√∫blico geral a respeito do andamento das obras do universo Homem-Aranha, para que se torne facilitada a captura de informa√ß√µes, possobilitando que haja um embasamento maior e mais r√°pido do que est√° interessante nas obras e deve continuar ocorrendo ou ainda ser melhorada, do que j√° n√£o est√° apresentando mais tanta notoriedade pelo p√∫blico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "No c√≥digo abaixo, realizou-se uma opera√ß√£o para verificar a qualidade do classificador e, para que isso fosse poss√≠vel, novas separa√ß√µes entre a base de Treinamento e Teste foram feitas. Desta maneira, foi consultada a documenta√ß√£o da biblioteca sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza(linha):\n",
    "    f = ','.join(limpa_marcacao1(separa_emoji(cleanup(linha)))).replace(',',' ')\n",
    "    return f\n",
    "\n",
    "# Unindo as tabelas em uma\n",
    "test_novo = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test_novo = test_novo.rename(columns={'Teste':'Total'})\n",
    "\n",
    "train_novo = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train_novo = train_novo.rename(columns={'Treinamento':'Total'})\n",
    "\n",
    "# Juntando em um √∫nico dataframe\n",
    "data = pd.concat([train_novo,test_novo])\n",
    "\n",
    "# Limpeza\n",
    "data['Limpo'] = data['Total'].apply(limpeza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, foram definidas algumas novas fun√ß√µes, com mesma performance de outras vistas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o com mesmo funcionamento da fun√ß√£o 'treinamento', vista anteriormente, mas agora para ser aplicada no dataframe desta etapa\n",
    "def treinamento_q(dataframe):\n",
    "    palavras = []\n",
    "    for linha in dataframe.Limpo:\n",
    "        for palavra in linha:\n",
    "            palavras.append(palavra)\n",
    "    return palavras\n",
    "\n",
    "# Fun√ß√£o com mesmo funcionamento da fun√ß√£o 'classifica', vista anteriormente, mas agora para ser aplicada no dataframe desta etapa\n",
    "def classifica_q(dataframe):\n",
    "    algoritmo = []\n",
    "    for frase in dataframe.Limpo:\n",
    "        probPalavraDadoR = 1\n",
    "        probPalavraDadoI = 1\n",
    "        for palavra in frase:\n",
    "            if not palavra in relevantes.keys(): \n",
    "                relevantes[palavra] = 0\n",
    "            if not palavra in irrelevantes.keys(): \n",
    "                irrelevantes[palavra] = 0\n",
    "\n",
    "            probPalavraDadoR *= (relevantes[palavra] + 1)/(total_relevantes + tamanho_vocabulario)\n",
    "            probPalavraDadoI *= (irrelevantes[palavra] + 1)/(total_irrelevantes + tamanho_vocabulario)\n",
    "        \n",
    "        probRDadoPalavra = probPalavraDadoR*probR\n",
    "        probIDadoPalavra = probPalavraDadoI*probI\n",
    "        \n",
    "        if probRDadoPalavra > probIDadoPalavra:\n",
    "            algoritmo.append(1)\n",
    "        else:\n",
    "            algoritmo.append(0)\n",
    "    return algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, abaixo, fez-se as repeti√ß√µes das separa√ß√µes dos tweets e a gera√ß√£o dos scores. Para isso, seguiu-se a mesma ideia, de um modo mais sussinto, das probabilidades vistas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "vdd_positivo = []\n",
    "vdd_negativo = [] \n",
    "precisao = []\n",
    "\n",
    "for i in range(0,100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[['Limpo','Classifica√ß√£o']],data['Classifica√ß√£o'], test_size=0.3)\n",
    "    \n",
    "    train1 = X_train[X_train['Classifica√ß√£o'] == 1]\n",
    "    train2 = X_train[X_train['Classifica√ß√£o'] == 0]\n",
    "    \n",
    "    palavras_treinamento = pd.Series(treinamento_q(X_train))\n",
    "    palavras_relevantes = pd.Series(treinamento_q(train1))\n",
    "    palavras_irrelevantes = pd.Series(treinamento_q(train2))\n",
    "    planilha_treinamento = palavras_treinamento.value_counts()\n",
    "    tamanho_vocabulario = len(planilha_treinamento)\n",
    "    \n",
    "    relevantes = palavras_relevantes.value_counts()\n",
    "    irrelevantes = palavras_irrelevantes.value_counts()\n",
    "    \n",
    "    total_relevantes = relevantes.sum()\n",
    "    total_irrelevantes = irrelevantes.sum()\n",
    "    total_palavras = total_relevantes + total_irrelevantes\n",
    "    \n",
    "    probR = total_relevantes/total_palavras \n",
    "    probI = total_irrelevantes/total_palavras\n",
    "\n",
    "    X_test.loc[:, 'Algoritmo'] = classifica_q(X_test)\n",
    "\n",
    "    verdadeiro_positivo=X_test.loc[(X_test['Algoritmo']==1)&(X_test['Classifica√ß√£o']==1),:].shape[0]\n",
    "    verdadeiro_negativo=X_test.loc[(X_test['Algoritmo']==0)&(X_test['Classifica√ß√£o']==0),:].shape[0]\n",
    "    acuracia=((verdadeiro_positivo+verdadeiro_negativo)/X_test.shape[0])*100\n",
    "        \n",
    "    vdd_positivo.append((verdadeiro_positivo/X_test.shape[0])*100)\n",
    "    vdd_negativo.append((verdadeiro_negativo/X_test.shape[0])*100)\n",
    "    precisao.append(acuracia) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score m√°ximo: 67.33%\n",
      "Score m√≠nimo: 49.33%\n",
      "Score m√©dio: 58.23%\n"
     ]
    }
   ],
   "source": [
    "print(\"Score m√°ximo: {0:.2f}%\".format(max(precisao)))\n",
    "print(\"Score m√≠nimo: {0:.2f}%\".format(min(precisao)))\n",
    "print(\"Score m√©dio: {0:.2f}%\".format(sum(precisao)/len(precisao)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "faixa = np.arange(47,75,1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(precisao, bins=faixa, edgecolor='black', density=False)\n",
    "plt.title('Frequ√™ncia / Scores / Modelo')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "plt.xlabel('Percentuais de acerto (%)')\n",
    "plt.xlim(47.5,70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir da observa√ß√£o do histograma plotado acima, √© poss√≠vel averiguar que este apresentou um comportamento aproximadamente sim√©trico, talvez com uma leve pos√≠vel assimetria, apesar de as medidas-resumo estarem bem aproximadas.\n",
    "\n",
    "Finalmente, conclui-se que a utiliza√ß√£o da base de dados uma √∫nica vez pode ser prejudicial para uma an√°lise mais detalhada do comportamento do algoritmo pois, quando isto √© aferido, percebe-se que ele tende a fazer uma classifica√ß√£o mais assertiva a percentuais mais altos, ou, a mais baixos. Assim, perde-se a chance de uma classifica√ß√£o mais elaborada do algoritmo, tendo-se em vista a matem√°tica por tr√°s do classificador Naive-Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
